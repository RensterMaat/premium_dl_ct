{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "from monai.data import Dataset\n",
    "from pytorch_lightning import LightningDataModule\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    LoadImaged,\n",
    "    EnsureChannelFirstd,\n",
    "    CenterSpatialCropd,\n",
    "    ToTensord\n",
    ")\n",
    "\n",
    "\n",
    "class DataModule:\n",
    "    def __init__(self, path_to_center_folders, prediction_target_file_path, target, test_center, batch_size=32):\n",
    "        self.root = Path(path_to_center_folders)\n",
    "        self.target = pd.read_csv(prediction_target_file_path).set_index('lesion')[target]\n",
    "        self.test_center = test_center\n",
    "        self.batch_size=batch_size\n",
    "        self.train_transform = Compose([\n",
    "            LoadImaged(keys=['img']),\n",
    "            EnsureChannelFirstd(keys=['img']),\n",
    "            CenterSpatialCropd(keys=['img'], roi_size=(96,96,96)),\n",
    "            ToTensord(keys=['img','label'])\n",
    "        ])\n",
    "        self.val_transform = self.train_transform\n",
    "        self.test_transform = self.train_transform\n",
    "        self.centers = [c.name for c in self.root.iterdir()]\n",
    "    \n",
    "    def setup(self):\n",
    "        dev_centers = [c for c in self.centers if not c == self.test_center]\n",
    "\n",
    "        # development data\n",
    "        dev_data = list(itertools.chain(*[\n",
    "            self.data_dir_to_dict(self.root / c) for c in dev_centers\n",
    "        ]))\n",
    "        train_data, val_data = train_test_split(dev_data, test_size=0.75)\n",
    "        self.train_dataset = Dataset(train_data, self.train_transform)\n",
    "        self.val_dataset = Dataset(val_data, self.val_transform)\n",
    "\n",
    "        # test data\n",
    "        test_data = self.data_dir_to_dict(self.root / self.test_center)\n",
    "        self.test_dataset = Dataset(test_data, self.test_transform)\n",
    "\n",
    "    def data_dir_to_dict(self, dir):\n",
    "        return [{'img':str(lesion_path),'label':self.target.loc[lesion_path.name]}\n",
    "            for lesion_path in dir.iterdir() if lesion_path.name in self.target.index\n",
    "        ]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=1)\n",
    "\n",
    "    \n",
    "dm = DataModule(\n",
    "    r'C:\\Users\\user\\data\\dl_radiomics\\preprocessed_3d',\n",
    "    r'C:\\Users\\user\\data\\tables\\lesion_followup_curated_v4.csv',\n",
    "    'liver',\n",
    "    'amphia'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 96, 96, 46)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.train_dataset[2]['img'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 160, in default_collate\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 160, in <dictcomp>\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 141, in default_collate\n    return torch.stack(batch, 0, out=out)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\monai\\data\\meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\_tensor.py\", line 1121, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 96, 96, 47] at entry 0 and [1, 96, 96, 28] at entry 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [131], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(\u001b[39miter\u001b[39;49m(dm\u001b[39m.\u001b[39;49mtrain_dataloader()))\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1376\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1375\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1376\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1402\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1402\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1403\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\_utils.py:461\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    458\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    459\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 461\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n    return self.collate_fn(data)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 160, in default_collate\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 160, in <dictcomp>\n    return elem_type({key: default_collate([d[key] for d in batch]) for key in elem})\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 141, in default_collate\n    return torch.stack(batch, 0, out=out)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\monai\\data\\meta_tensor.py\", line 249, in __torch_function__\n    ret = super().__torch_function__(func, types, args, kwargs)\n  File \"c:\\Users\\user\\anaconda3\\envs\\rob\\lib\\site-packages\\torch\\_tensor.py\", line 1121, in __torch_function__\n    ret = func(*args, **kwargs)\nRuntimeError: stack expects each tensor to be equal size, but got [1, 96, 96, 47] at entry 0 and [1, 96, 96, 28] at entry 4\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(dm.train_dataloader()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('rob')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ca38a36c27a6fda9f36158854ae787c0f5f98b555e1563ed4f17965dab62153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
